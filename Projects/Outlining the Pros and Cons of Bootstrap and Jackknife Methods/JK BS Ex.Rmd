---
title: "JK BS Example"
author: "Samuel Greeman"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Since it is hard to manufacture examples of bootstrapping and jackknifing, we will be following closely with a jackknifing example from the math department at montana.edu and a bootstrapping example from ucla.edu, both of which can be found in references. First, we will start with the jackknife example:

## Reading in the data
```{r, echo=FALSE, message=FALSE}
data.X <- c(4.23, 1.30, 0.99, 2.41, 1.87, 3.28, 0.67, 3.12, 0.71, 0.82,
       0.67, 0.88, 2.14, 0.29, 2.41, 3.09, 1.02, 0.57, 0.46, 1.381, 0.122)
mean(data.X)
```

## Jackknife the mean and bias correction
```{r}
library(bootstrap)
mean_j <- jackknife(data.X, mean)
mean_j

adj_mean_j = mean(data.X) - mean_j$jack.bias
adj_mean_j
```
As you can, see our boot-strapped mean is the same as our
sample mean. You can also see that there is no bias here in this data,
but jackknifing did change our values. Let's see what happens when we do
the jackknifing on the variance.

## Jackknife the variance and bias correction
```{r}
var(data.X)
var_j <- jackknife(data.X, var)
var_j
adj_var_j = var(data.X) - var_j$jack.bias
adj_var_j
```
Once again, we see that our variance was unbiased. Again, our sample values
were altered, but the result was not. Jackknifing sometimes does not tell you 
much, but that means that the estimator you are using is good because
it is unbiased.

Let's move onto the bootstrapping example, which uses a data set from UCLA.

## Read in the data
```{r, echo=FALSE, message=FALSE}
library(boot)
data.Y <- read.table("https://stats.idre.ucla.edu/stat/data/hsb2.csv", sep=",", header=T)
```

After we read in the data, we set our function that we will use to obtain statistics to bootstrap. We chose
to use correlation as our statistic:

```{r}
cor_fun <- function(d, i){
	d2 <- d[i,]
	return(cor(d2$write, d2$math))
}
```

In this example we will use our number of samples as 500, and here, R
calculates our estimate, bias, and standard error for this bootstrap:

## Bootstrap execution
```{r}
boot_results <- boot(data.Y, cor_fun, R = 500)
boot_results
```
As you can see, this method gives us a very precise estimate of all of
our metrics. 
